---
title: 如何選擇 ML.NET 演算法
description: 了解如何選擇機器學習模型的 ML.NET 演算法
ms.topic: overview
ms.date: 06/05/2019
ms.openlocfilehash: 04cf191401c7c25f1fa341acaf9312dc19752260
ms.sourcegitcommit: e301979e3049ce412d19b094c60ed95b316a8f8c
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 12/16/2020
ms.locfileid: "97593086"
---
# <a name="how-to-choose-an-mlnet-algorithm"></a><span data-ttu-id="a0c55-103">如何選擇 ML.NET 演算法</span><span class="sxs-lookup"><span data-stu-id="a0c55-103">How to choose an ML.NET algorithm</span></span>

<span data-ttu-id="a0c55-104">針對每項 [ML.NET 工作](resources/tasks.md)，有多個定型演算法可供選擇。</span><span class="sxs-lookup"><span data-stu-id="a0c55-104">For each [ML.NET task](resources/tasks.md), there are multiple training algorithms to choose from.</span></span> <span data-ttu-id="a0c55-105">要選擇哪一個，取決於您嘗試解決的問題、您資料的特性，以及您目前可使用的計算和儲存資源。</span><span class="sxs-lookup"><span data-stu-id="a0c55-105">Which one to choose depends on the problem you are trying to solve, the characteristics of your data, and the compute and storage resources you have available.</span></span> <span data-ttu-id="a0c55-106">請務必注意，定型的機器學習模型是一種反覆運算程序。</span><span class="sxs-lookup"><span data-stu-id="a0c55-106">It is important to note that training a machine learning model is an iterative process.</span></span> <span data-ttu-id="a0c55-107">您可能需要嘗試多種演算法，找出最適合的那一種。</span><span class="sxs-lookup"><span data-stu-id="a0c55-107">You might need to try multiple algorithms to find the one that works best.</span></span>

<span data-ttu-id="a0c55-108">演算法作用於 **特性**。</span><span class="sxs-lookup"><span data-stu-id="a0c55-108">Algorithms operate on **features**.</span></span> <span data-ttu-id="a0c55-109">特性是計算輸入資料所得出的數值。</span><span class="sxs-lookup"><span data-stu-id="a0c55-109">Features are numerical values computed from your input data.</span></span> <span data-ttu-id="a0c55-110">它們是機器學習演算法的最佳輸入。</span><span class="sxs-lookup"><span data-stu-id="a0c55-110">They are optimal inputs for machine learning algorithms.</span></span> <span data-ttu-id="a0c55-111">您使用一或多種[資料轉換](resources/transforms.md)，將未經處理的輸入資料轉換成特性。</span><span class="sxs-lookup"><span data-stu-id="a0c55-111">You transform your raw input data into features using one or more [data transforms](resources/transforms.md).</span></span> <span data-ttu-id="a0c55-112">例如，文字資料會轉換成一組字數統計和字詞組合統計。</span><span class="sxs-lookup"><span data-stu-id="a0c55-112">For example, text data is transformed into a set of word counts and word combination counts.</span></span> <span data-ttu-id="a0c55-113">一旦使用資料轉換從未經處理的資料類型擷取特性，它們就稱為 **凸顯**。</span><span class="sxs-lookup"><span data-stu-id="a0c55-113">Once the features have been extracted from a raw data type using data transforms, they are referred to as **featurized**.</span></span> <span data-ttu-id="a0c55-114">例如，凸顯的文字或影像資料。</span><span class="sxs-lookup"><span data-stu-id="a0c55-114">For example, featurized text, or featurized image data.</span></span>

## <a name="trainer--algorithm--task"></a><span data-ttu-id="a0c55-115">定型器 = 演算法 + 工作</span><span class="sxs-lookup"><span data-stu-id="a0c55-115">Trainer = Algorithm + Task</span></span>

<span data-ttu-id="a0c55-116">演算法是為產生 **模型** 所執行的數學。</span><span class="sxs-lookup"><span data-stu-id="a0c55-116">An algorithm is the math that executes to produce a **model**.</span></span> <span data-ttu-id="a0c55-117">不同演算法產生不同特性的模型。</span><span class="sxs-lookup"><span data-stu-id="a0c55-117">Different algorithms produce models with different characteristics.</span></span>

<span data-ttu-id="a0c55-118">使用 ML.NET，相同演算法可以套用到不同的工作。</span><span class="sxs-lookup"><span data-stu-id="a0c55-118">With ML.NET, the same algorithm can be applied to different tasks.</span></span> <span data-ttu-id="a0c55-119">例如，隨機雙重座標上升可用於二元分類、多元分類和回歸。</span><span class="sxs-lookup"><span data-stu-id="a0c55-119">For example, Stochastic Dual Coordinate Ascent can be used for Binary Classification, Multiclass Classification, and Regression.</span></span> <span data-ttu-id="a0c55-120">不同之處在於如何解譯演算法的輸出，使符合工作。</span><span class="sxs-lookup"><span data-stu-id="a0c55-120">The difference is in how the output of the algorithm is interpreted to match the task.</span></span>

<span data-ttu-id="a0c55-121">針對每個演算法/工作組合，ML.NET 會提供執行定型演算法的元件，並進行轉譯。</span><span class="sxs-lookup"><span data-stu-id="a0c55-121">For each algorithm/task combination, ML.NET provides a component that executes the training algorithm and makes the interpretation.</span></span> <span data-ttu-id="a0c55-122">這些元件稱為「定型器」。</span><span class="sxs-lookup"><span data-stu-id="a0c55-122">These components are called trainers.</span></span> <span data-ttu-id="a0c55-123">例如，<xref:Microsoft.ML.Trainers.SdcaRegressionTrainer> 使用 **StochasticDualCoordinatedAscent** 演算法套用至 **迴歸** 工作。</span><span class="sxs-lookup"><span data-stu-id="a0c55-123">For example, the <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer> uses the **StochasticDualCoordinatedAscent** algorithm applied to the **Regression** task.</span></span>

## <a name="linear-algorithms"></a><span data-ttu-id="a0c55-124">線性演算法</span><span class="sxs-lookup"><span data-stu-id="a0c55-124">Linear algorithms</span></span>

<span data-ttu-id="a0c55-125">線性演算法產生的模型會計算輸入資料和一組 **權數** 之線性組合的 **分數**。</span><span class="sxs-lookup"><span data-stu-id="a0c55-125">Linear algorithms produce a model that calculates **scores** from a linear combination of the input data and a set of **weights**.</span></span> <span data-ttu-id="a0c55-126">權數是在定型期間評估的模型參數。</span><span class="sxs-lookup"><span data-stu-id="a0c55-126">The weights are parameters of the model estimated during training.</span></span>

<span data-ttu-id="a0c55-127">線性演算法適用於[線性可分](https://en.wikipedia.org/wiki/Linear_separability)的特性。</span><span class="sxs-lookup"><span data-stu-id="a0c55-127">Linear algorithms work well for features that are [linearly separable](https://en.wikipedia.org/wiki/Linear_separability).</span></span>

<span data-ttu-id="a0c55-128">使用線性演算法定型之前，應先將特性標準化。</span><span class="sxs-lookup"><span data-stu-id="a0c55-128">Before training with a linear algorithm, the features should be normalized.</span></span> <span data-ttu-id="a0c55-129">這可防止某項功能對結果產生比其他功能更多的影響。</span><span class="sxs-lookup"><span data-stu-id="a0c55-129">This prevents one feature from having more influence over the result than others.</span></span>

<span data-ttu-id="a0c55-130">一般而言，線性演算法可調整、快速、便宜，以及預測成本低廉。</span><span class="sxs-lookup"><span data-stu-id="a0c55-130">In general, linear algorithms are scalable, fast, cheap to train, and cheap to predict.</span></span> <span data-ttu-id="a0c55-131">它們可以調整特色數目，約為定型資料集的大小。</span><span class="sxs-lookup"><span data-stu-id="a0c55-131">They scale by the number of features and approximately by the size of the training data set.</span></span>

<span data-ttu-id="a0c55-132">線性演算法對定型資料進行多次傳遞。</span><span class="sxs-lookup"><span data-stu-id="a0c55-132">Linear algorithms make multiple passes over the training data.</span></span> <span data-ttu-id="a0c55-133">如果您的資料集符合記憶體，則在附加訓練課程之前將快取 [檢查點](xref:Microsoft.ML.LearningPipelineExtensions.AppendCacheCheckpoint%2A) 新增至 ML.NET 管線，可讓定型執行速度更快。</span><span class="sxs-lookup"><span data-stu-id="a0c55-133">If your dataset fits into memory, then adding a [cache checkpoint](xref:Microsoft.ML.LearningPipelineExtensions.AppendCacheCheckpoint%2A) to your ML.NET pipeline before appending the trainer will make the training run faster.</span></span>

<span data-ttu-id="a0c55-134">**線性定型器**</span><span class="sxs-lookup"><span data-stu-id="a0c55-134">**Linear Trainers**</span></span>

|<span data-ttu-id="a0c55-135">演算法</span><span class="sxs-lookup"><span data-stu-id="a0c55-135">Algorithm</span></span>|<span data-ttu-id="a0c55-136">屬性</span><span class="sxs-lookup"><span data-stu-id="a0c55-136">Properties</span></span>|<span data-ttu-id="a0c55-137">定型器</span><span class="sxs-lookup"><span data-stu-id="a0c55-137">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="a0c55-138">平均感知器</span><span class="sxs-lookup"><span data-stu-id="a0c55-138">Averaged perceptron</span></span>|<span data-ttu-id="a0c55-139">最適合文字分類</span><span class="sxs-lookup"><span data-stu-id="a0c55-139">Best for text classification</span></span>|<xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>|
|<span data-ttu-id="a0c55-140">隨機對偶座標上升法</span><span class="sxs-lookup"><span data-stu-id="a0c55-140">Stochastic dual coordinated ascent</span></span>|<span data-ttu-id="a0c55-141">好的預設效能不需要微調</span><span class="sxs-lookup"><span data-stu-id="a0c55-141">Tuning not needed for good default performance</span></span>|<span data-ttu-id="a0c55-142"><xref:Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="a0c55-142"><xref:Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer></span></span>|
|<span data-ttu-id="a0c55-143">L-BFGS</span><span class="sxs-lookup"><span data-stu-id="a0c55-143">L-BFGS</span></span>|<span data-ttu-id="a0c55-144">當特性數目很大時使用。</span><span class="sxs-lookup"><span data-stu-id="a0c55-144">Use when number of features is large.</span></span> <span data-ttu-id="a0c55-145">產生羅吉斯迴歸定型統計資料，但不像 AveragedPerceptronTrainer 縮放自如</span><span class="sxs-lookup"><span data-stu-id="a0c55-145">Produces logistic regression training statistics, but doesn't scale as well as the AveragedPerceptronTrainer</span></span>|<span data-ttu-id="a0c55-146"><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.LbfgsPoissonRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="a0c55-146"><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.LbfgsPoissonRegressionTrainer></span></span>|
|<span data-ttu-id="a0c55-147">符號隨機梯度下降</span><span class="sxs-lookup"><span data-stu-id="a0c55-147">Symbolic stochastic gradient descent</span></span>|<span data-ttu-id="a0c55-148">最快速且最精確的線性二元分類定型器。</span><span class="sxs-lookup"><span data-stu-id="a0c55-148">Fastest and most accurate linear binary classification trainer.</span></span> <span data-ttu-id="a0c55-149">可隨處理器數目調整</span><span class="sxs-lookup"><span data-stu-id="a0c55-149">Scales well with number of processors</span></span>|<xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>|

## <a name="decision-tree-algorithms"></a><span data-ttu-id="a0c55-150">決策樹演算法</span><span class="sxs-lookup"><span data-stu-id="a0c55-150">Decision tree algorithms</span></span>

<span data-ttu-id="a0c55-151">決策樹演算法建立的模型，包含一系列的決策：所有資料值的有效流程圖。</span><span class="sxs-lookup"><span data-stu-id="a0c55-151">Decision tree algorithms create a model that contains a series of decisions: effectively a flow chart through the data values.</span></span>

<span data-ttu-id="a0c55-152">特性不需要為線性可分，也可以使用這種演算法。</span><span class="sxs-lookup"><span data-stu-id="a0c55-152">Features do not need to be linearly separable to use this type of algorithm.</span></span> <span data-ttu-id="a0c55-153">而且特性不需要標準化，因為在決策流程中會單獨使用特性向量的個別值。</span><span class="sxs-lookup"><span data-stu-id="a0c55-153">And features do not need to be normalized, because the individual values in the feature vector are used independently in the decision process.</span></span>

<span data-ttu-id="a0c55-154">決策樹演算法通常非常精確。</span><span class="sxs-lookup"><span data-stu-id="a0c55-154">Decision tree algorithms are generally very accurate.</span></span>

<span data-ttu-id="a0c55-155">除了一般化累加模型 (GAM) 外，樹狀模型在特性數目很大時會欠缺解釋性。</span><span class="sxs-lookup"><span data-stu-id="a0c55-155">Except for Generalized Additive Models (GAMs), tree models can lack explainability when the number of features is large.</span></span>

<span data-ttu-id="a0c55-156">決策樹演算法需要更多資源，且不像線性演算法縮放自如。</span><span class="sxs-lookup"><span data-stu-id="a0c55-156">Decision tree algorithms take more resources and do not scale as well as linear ones do.</span></span> <span data-ttu-id="a0c55-157">它們也很適合貼近記憶體的資料集。</span><span class="sxs-lookup"><span data-stu-id="a0c55-157">They do perform well on datasets that can fit into memory.</span></span>

<span data-ttu-id="a0c55-158">促進式決策樹是一整團的小型樹狀結構，其中每個樹狀結構都會評分輸入資料，並將分數傳遞到下一個樹狀結構，以產生更好的分數，整體中的每個樹狀結構都可以改善前一個樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="a0c55-158">Boosted decision trees are an ensemble of small trees where each tree scores the input data and passes the score onto the next tree to produce a better score, and so on, where each tree in the ensemble improves on the previous.</span></span>

<span data-ttu-id="a0c55-159">**決策樹定型器**</span><span class="sxs-lookup"><span data-stu-id="a0c55-159">**Decision tree trainers**</span></span>

|<span data-ttu-id="a0c55-160">演算法</span><span class="sxs-lookup"><span data-stu-id="a0c55-160">Algorithm</span></span>|<span data-ttu-id="a0c55-161">屬性</span><span class="sxs-lookup"><span data-stu-id="a0c55-161">Properties</span></span>|<span data-ttu-id="a0c55-162">定型器</span><span class="sxs-lookup"><span data-stu-id="a0c55-162">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="a0c55-163">輕量型梯度提升機器</span><span class="sxs-lookup"><span data-stu-id="a0c55-163">Light gradient boosted machine</span></span>|<span data-ttu-id="a0c55-164">最快速且最精確的二元分類樹狀定型器。</span><span class="sxs-lookup"><span data-stu-id="a0c55-164">Fastest and most accurate of the binary classification tree trainers.</span></span> <span data-ttu-id="a0c55-165">微調程度高</span><span class="sxs-lookup"><span data-stu-id="a0c55-165">Highly tunable</span></span>|<span data-ttu-id="a0c55-166"><xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer></span><span class="sxs-lookup"><span data-stu-id="a0c55-166"><xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer></span></span>|
|<span data-ttu-id="a0c55-167">快速的樹狀結構</span><span class="sxs-lookup"><span data-stu-id="a0c55-167">Fast tree</span></span>|<span data-ttu-id="a0c55-168">用於特徵化影像資料。</span><span class="sxs-lookup"><span data-stu-id="a0c55-168">Use for featurized image data.</span></span> <span data-ttu-id="a0c55-169">復原不對稱的資料。</span><span class="sxs-lookup"><span data-stu-id="a0c55-169">Resilient to unbalanced data.</span></span> <span data-ttu-id="a0c55-170">微調程度高</span><span class="sxs-lookup"><span data-stu-id="a0c55-170">Highly tunable</span></span> | <span data-ttu-id="a0c55-171"><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeTweedieTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRankingTrainer></span><span class="sxs-lookup"><span data-stu-id="a0c55-171"><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeTweedieTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRankingTrainer></span></span>|
|<span data-ttu-id="a0c55-172">快速樹系</span><span class="sxs-lookup"><span data-stu-id="a0c55-172">Fast forest</span></span>|<span data-ttu-id="a0c55-173">適用於有很多雜訊的資料</span><span class="sxs-lookup"><span data-stu-id="a0c55-173">Works well with noisy data</span></span>|<span data-ttu-id="a0c55-174"><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="a0c55-174"><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer></span></span>|
|<span data-ttu-id="a0c55-175">一般化累加模型 (GAM)</span><span class="sxs-lookup"><span data-stu-id="a0c55-175">Generalized additive model (GAM)</span></span>|<span data-ttu-id="a0c55-176">最適合處理適用樹狀演算法，但解釋性優先的問題</span><span class="sxs-lookup"><span data-stu-id="a0c55-176">Best for problems that perform well with tree algorithms but where explainability is a priority</span></span>|<span data-ttu-id="a0c55-177"><xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.GamRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="a0c55-177"><xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.GamRegressionTrainer></span></span>|

## <a name="matrix-factorization"></a><span data-ttu-id="a0c55-178">矩陣分解</span><span class="sxs-lookup"><span data-stu-id="a0c55-178">Matrix factorization</span></span>

|<span data-ttu-id="a0c55-179">屬性</span><span class="sxs-lookup"><span data-stu-id="a0c55-179">Properties</span></span>|<span data-ttu-id="a0c55-180">定型器</span><span class="sxs-lookup"><span data-stu-id="a0c55-180">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="a0c55-181">最適合大型資料集的分類疏鬆資料</span><span class="sxs-lookup"><span data-stu-id="a0c55-181">Best for sparse categorical data, with large datasets</span></span>|<xref:Microsoft.ML.Trainers.FieldAwareFactorizationMachineTrainer>|

## <a name="meta-algorithms"></a><span data-ttu-id="a0c55-182">中繼演算法</span><span class="sxs-lookup"><span data-stu-id="a0c55-182">Meta algorithms</span></span>

<span data-ttu-id="a0c55-183">這些定型者會從二元講師建立多元講師。</span><span class="sxs-lookup"><span data-stu-id="a0c55-183">These trainers create a multiclass trainer from a binary trainer.</span></span> <span data-ttu-id="a0c55-184">搭配使用 <xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer>、<xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>、<xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer>、<xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer>。</span><span class="sxs-lookup"><span data-stu-id="a0c55-184">Use with <xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>, <xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer>.</span></span>

|<span data-ttu-id="a0c55-185">演算法</span><span class="sxs-lookup"><span data-stu-id="a0c55-185">Algorithm</span></span>|<span data-ttu-id="a0c55-186">屬性</span><span class="sxs-lookup"><span data-stu-id="a0c55-186">Properties</span></span>|<span data-ttu-id="a0c55-187">定型器</span><span class="sxs-lookup"><span data-stu-id="a0c55-187">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="a0c55-188">一對多</span><span class="sxs-lookup"><span data-stu-id="a0c55-188">One versus all</span></span>|<span data-ttu-id="a0c55-189">此多元分類器每類別定型一個二元分類器，從所有其他類別中區分出該類別。</span><span class="sxs-lookup"><span data-stu-id="a0c55-189">This multiclass classifier trains one binary classifier for each class, which distinguishes that class from all other classes.</span></span> <span data-ttu-id="a0c55-190">規模受限於要分類的類別數目</span><span class="sxs-lookup"><span data-stu-id="a0c55-190">Is limited in scale by the number of classes to categorize</span></span>|[<span data-ttu-id="a0c55-191">OneVersusAllTrainer\<BinaryClassificationTrainer></span><span class="sxs-lookup"><span data-stu-id="a0c55-191">OneVersusAllTrainer\<BinaryClassificationTrainer></span></span>](xref:Microsoft.ML.Trainers.OneVersusAllTrainer) |
|<span data-ttu-id="a0c55-192">成對結合</span><span class="sxs-lookup"><span data-stu-id="a0c55-192">Pairwise coupling</span></span>|<span data-ttu-id="a0c55-193">此多元分類器針對每對類別定型二元分類演算法。</span><span class="sxs-lookup"><span data-stu-id="a0c55-193">This multiclass classifier trains a binary classification algorithm on each pair of classes.</span></span> <span data-ttu-id="a0c55-194">規模受限於類別數目，因為必須定型每對類別的組合。</span><span class="sxs-lookup"><span data-stu-id="a0c55-194">Is limited in scale by the number of classes, as each combination of two classes must be trained.</span></span>|[<span data-ttu-id="a0c55-195">PairwiseCouplingTrainer\<BinaryClassificationTrainer></span><span class="sxs-lookup"><span data-stu-id="a0c55-195">PairwiseCouplingTrainer\<BinaryClassificationTrainer></span></span>](xref:Microsoft.ML.Trainers.PairwiseCouplingTrainer)|

## <a name="k-means"></a><span data-ttu-id="a0c55-196">K-Means</span><span class="sxs-lookup"><span data-stu-id="a0c55-196">K-Means</span></span>

|<span data-ttu-id="a0c55-197">屬性</span><span class="sxs-lookup"><span data-stu-id="a0c55-197">Properties</span></span>|<span data-ttu-id="a0c55-198">定型器</span><span class="sxs-lookup"><span data-stu-id="a0c55-198">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="a0c55-199">用於叢集</span><span class="sxs-lookup"><span data-stu-id="a0c55-199">Use for clustering</span></span>|<xref:Microsoft.ML.Trainers.KMeansTrainer>|

## <a name="principal-component-analysis"></a><span data-ttu-id="a0c55-200">主體元件分析</span><span class="sxs-lookup"><span data-stu-id="a0c55-200">Principal component analysis</span></span>

|<span data-ttu-id="a0c55-201">屬性</span><span class="sxs-lookup"><span data-stu-id="a0c55-201">Properties</span></span>|<span data-ttu-id="a0c55-202">定型器</span><span class="sxs-lookup"><span data-stu-id="a0c55-202">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="a0c55-203">用於異常偵測</span><span class="sxs-lookup"><span data-stu-id="a0c55-203">Use for anomaly detection</span></span>|<xref:Microsoft.ML.Trainers.RandomizedPcaTrainer>|

## <a name="naive-bayes"></a><span data-ttu-id="a0c55-204">貝氏機率分類</span><span class="sxs-lookup"><span data-stu-id="a0c55-204">Naive Bayes</span></span>

|<span data-ttu-id="a0c55-205">屬性</span><span class="sxs-lookup"><span data-stu-id="a0c55-205">Properties</span></span>|<span data-ttu-id="a0c55-206">定型器</span><span class="sxs-lookup"><span data-stu-id="a0c55-206">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="a0c55-207">當特性獨立存在且定型資料集很小時，請使用此多元分類定型器。</span><span class="sxs-lookup"><span data-stu-id="a0c55-207">Use this multi-class classification trainer when the features are independent, and the training dataset is small.</span></span>|<xref:Microsoft.ML.Trainers.NaiveBayesMulticlassTrainer>|

## <a name="prior-trainer"></a><span data-ttu-id="a0c55-208">舊的定型器</span><span class="sxs-lookup"><span data-stu-id="a0c55-208">Prior Trainer</span></span>

|<span data-ttu-id="a0c55-209">屬性</span><span class="sxs-lookup"><span data-stu-id="a0c55-209">Properties</span></span>|<span data-ttu-id="a0c55-210">定型器</span><span class="sxs-lookup"><span data-stu-id="a0c55-210">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="a0c55-211">使用此二元分類定型器建立其他定型器的效能基準。</span><span class="sxs-lookup"><span data-stu-id="a0c55-211">Use this binary classification trainer to baseline the performance of other trainers.</span></span> <span data-ttu-id="a0c55-212">為有效率，其他定型器的計量應該比舊定型器好。</span><span class="sxs-lookup"><span data-stu-id="a0c55-212">To be effective, the metrics of the other trainers should be better than the prior trainer.</span></span> |<xref:Microsoft.ML.Trainers.PriorTrainer>|
